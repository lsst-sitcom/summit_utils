# This file is part of summit_utils.
#
# Developed for the LSST Data Management System.
# This product includes software developed by the LSST Project
# (https://www.lsst.org).
# See the COPYRIGHT file at the top-level directory of this distribution
# for details of code ownership.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

import re
import enum
import itertools
import logging
import pandas as pd
import numpy as np
import humanize
from dataclasses import dataclass, field
from astropy.time import Time
from matplotlib.ticker import FuncFormatter
import matplotlib.dates as mdates
import matplotlib.pyplot as plt
from lsst.utils.iteration import ensure_iterable

from .enums import AxisMotionState, PowerState
from .blockUtils import BlockParser
from .utils import getCurrentDayObs_int, dayObsIntToString
from .efdUtils import (getEfdData,
                       makeEfdClient,
                       efdTimestampToAstropy,
                       COMMAND_ALIASES,
                       getDayObsForTime,
                       getDayObsStartTime,
                       getDayObsEndTime,
                       )

__all__ = (
    'TMAStateMachine',
    'TMAEvent',
    'TMAEventMaker',
    'TMAState',
    'AxisMotionState',
    'PowerState',
    'getSlewsFromEventList',
    'getTracksFromEventList',
    'getTorqueMaxima',
)

# we don't want to use `None` for a no data sentinel because dict.get('key')
# returns None if the key isn't present, and also we need to mark that the data
# was queried for and no data was found, whereas the key not being present
# means that we've not yet looked for the data.
NO_DATA_SENTINEL = "NODATA"


def getSlewsFromEventList(events):
    """Get the slew events from a list of TMAEvents.

    Parameters
    ----------
    events : `list` of `lsst.summit.utils.tmaUtils.TMAEvent`
        The list of events to filter.

    Returns
    -------
    events : `list` of `lsst.summit.utils.tmaUtils.TMAEvent`
        The filtered list of events.
    """
    return [e for e in events if e.type == TMAState.SLEWING]


def getTracksFromEventList(events):
    """Get the tracking events from a list of TMAEvents.

    Parameters
    ----------
    events : `list` of `lsst.summit.utils.tmaUtils.TMAEvent`
        The list of events to filter.

    Returns
    -------
    events : `list` of `lsst.summit.utils.tmaUtils.TMAEvent`
        The filtered list of events.
    """
    return [e for e in events if e.type == TMAState.TRACKING]


def getTorqueMaxima(table):
    """Print the maximum positive and negative azimuth and elevation torques.

    Designed to be used with the table as downloaded from RubinTV.

    Parameters
    ----------
    table : `pd.DataFrame`
        The table of data to use, as generated by Rapid Analysis.
    """
    for axis in ['elevation', 'azimuth']:
        col = f'Largest {axis} torque'
        maxPos = np.argmax(table[col])
        maxVal = table[col].iloc[maxPos]
        print(f"Max positive {axis:9} torque during seqNum {maxPos:>4}: {maxVal/1000:>7.1f}kNm")
        minPos = np.argmin(table[col])
        minVal = table[col].iloc[minPos]
        print(f"Max negative {axis:9} torque during seqNum {minPos:>4}: {minVal/1000:>7.1f}kNm")


def getAzimuthElevationDataForEvent(client, event, prePadding=0, postPadding=0):
    """Get the data for the az/el telemetry topics for a given TMAEvent.

    Parameters
    ----------
    client : `lsst_efd_client.efd_helper.EfdClient`
        The EFD client to use.
    event : `lsst.summit.utils.tmaUtils.TMAEvent`
        The event to get the data for.
    prePadding : `float`, optional
        The amount of time to pad the event with before the start time, in
        seconds.
    postPadding : `float`, optional
        The amount of time to pad the event with after the end time, in
        seconds.

    Returns
    -------
    azimuthData : `pd.DataFrame`
        The azimuth data for the specified event.
    elevationData : `pd.DataFrame`
        The elevation data for the specified event.
    """
    azimuthData = getEfdData(client,
                             'lsst.sal.MTMount.azimuth',
                             event=event,
                             prePadding=prePadding,
                             postPadding=postPadding)
    elevationData = getEfdData(client,
                               'lsst.sal.MTMount.elevation',
                               event=event,
                               prePadding=prePadding,
                               postPadding=postPadding)
    if event.type.name == 'TRACKING':
        # Need to pad this data for the interpolation to work right
        pointingData = getEfdData(client,
                                  'lsst.sal.MTPtg.currentTargetStatus',
                                  event=event,
                                  prePadding=1.0,
                                  postPadding=1.0)

        az_times = azimuthData['timestamp'].values
        el_times = elevationData['timestamp'].values
        ptg_times = pointingData['timestamp'].values
        az_values = azimuthData['actualPosition'].values
        el_values = elevationData['actualPosition'].values
        # Need to interpolate because demand and actual data streams 
        # have different lengths
        az_demand_interp = np.interp(az_times, ptg_times, pointingData['demandAz'])
        el_demand_interp = np.interp(el_times, ptg_times, pointingData['demandEl'])
        az_error = (az_values - az_demand_interp) * 3600
        el_error = (el_values - el_demand_interp) * 3600
        # Because of small timebase errors, there can be an offset in the errors.
        # I take this out by subtracting the median of the errors.
        # This is a fudge, but I think better than the polynomial fit.
        az_error -= np.median(az_error)
        el_error -= np.median(el_error)
        azimuthData['azError'] = az_error
        elevationData['elError'] = el_error

    return azimuthData, elevationData


def plotEvent(client, event, fig=None, prePadding=0, postPadding=0, commands={},
              azimuthData=None, elevationData=None):
    """Plot the TMA axis positions over the course of a given TMAEvent.

    Plots the axis motion profiles for the given event, with optional padding
    at the start and end of the event. If the data is provided via the
    azimuthData and elevationData parameters, it will be used, otherwise it
    will be queried from the EFD.

    Optionally plots any commands issued during or around the event, if these
    are supplied. Commands are supplied as a dictionary of the command topic
    strings, with values as astro.time.Time objects at which the command was
    issued.

    Parameters
    ----------
    client : `lsst_efd_client.efd_helper.EfdClient`
        The EFD client to use.
    event : `lsst.summit.utils.tmaUtils.TMAEvent`
        The event to plot.
    fig : `matplotlib.figure.Figure`, optional
        The figure to plot on. If not specified, a new figure will be created.
    prePadding : `float`, optional
        The amount of time to pad the event with before the start time, in
        seconds.
    postPadding : `float`, optional
        The amount of time to pad the event with after the end time, in
        seconds.
    commands : `dict` of `str` : `astropy.time.Time`, optional
        A dictionary of commands to plot on the figure. The keys are the topic
        names, and the values are the times at which the commands were sent.
    azimuthData : `pd.DataFrame`, optional
        The azimuth data to plot. If not specified, it will be queried from the
        EFD.
    elevationData : `pd.DataFrame`, optional
        The elevation data to plot. If not specified, it will be queried from
        the EFD.
    pointingData : `pd.DataFrame`, optional
        The az/el target data to plot. If not specified, it will be queried from
        the EFD.

    Returns
    -------
    fig : `matplotlib.figure.Figure`
        The figure on which the plot was made.
    """
    def tickFormatter(value, tick_number):
        # Convert the value to a string without subtracting large numbers
        # tick_number is unused.
        return f"{value:.2f}"

    # plot any commands we might have
    if not isinstance(commands, dict):
        raise TypeError('commands must be a dict of command names with values as'
                        ' astropy.time.Time values')

    if fig is None:
        fig = plt.figure(figsize=(10, 8))
        log = logging.getLogger(__name__)
        log.warning("Making new matplotlib figure - if this is in a loop you're going to have a bad time."
                    " Pass in a figure with fig = plt.figure(figsize=(10, 8)) to avoid this warning.")

    fig.clear()
    if event.type.name == 'TRACKING':
        ax1, ax1p5, ax2 = fig.subplots(3,
                                       sharex=True,
                                       gridspec_kw={'wspace': 0,
                                                    'hspace': 0,
                                                    'height_ratios': [2.5, 1, 1]})
    else:
        ax1, ax2 = fig.subplots(2,
                                sharex=True,
                                gridspec_kw={'wspace': 0,
                                             'hspace': 0,
                                             'height_ratios': [2.5, 1]})

    if azimuthData is None or elevationData is None:
        azimuthData, elevationData = getAzimuthElevationDataForEvent(client,
                                                                     event,
                                                                     prePadding=prePadding,
                                                                     postPadding=postPadding)

    # Use the native color cycle for the lines. Because they're on different
    # axes they don't cycle by themselves
    lineColors = [p['color'] for p in plt.rcParams['axes.prop_cycle']]
    colorCounter = 0

    ax1.plot(azimuthData['actualPosition'], label='Azimuth position', c=lineColors[colorCounter])
    colorCounter += 1
    ax1.yaxis.set_major_formatter(FuncFormatter(tickFormatter))
    ax1.set_ylabel('Azimuth (degrees)')

    ax1_twin = ax1.twinx()
    ax1_twin.plot(elevationData['actualPosition'], label='Elevation position', c=lineColors[colorCounter])
    colorCounter += 1
    ax1_twin.yaxis.set_major_formatter(FuncFormatter(tickFormatter))
    ax1_twin.set_ylabel('Elevation (degrees)')
    ax1.set_xticks([])  # remove x tick labels on the hidden upper x-axis

    ax2_twin = ax2.twinx()
    ax2.plot(azimuthData['actualTorque'], label='Azimuth torque', c=lineColors[colorCounter])
    colorCounter += 1
    ax2_twin.plot(elevationData['actualTorque'], label='Elevation torque', c=lineColors[colorCounter])
    colorCounter += 1
    ax2.set_ylabel('Azimuth torque (Nm)')
    ax2_twin.set_ylabel('Elevation torque (Nm)')
    ax2.set_xlabel('Time (UTC)')  # yes, it really is UTC, matplotlib converts this automatically!

    # put the ticks at an angle, and right align with the tick marks
    ax2.set_xticks(ax2.get_xticks())  # needed to supress a user warning
    xlabels = ax2.get_xticks()
    ax2.set_xticklabels(xlabels, rotation=40, ha='right')
    ax2.xaxis.set_major_locator(mdates.AutoDateLocator())
    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))

    if event.type.name == 'TRACKING':
        # Calculate RMS
        az_vals = azimuthData['azError'].values
        el_vals = elevationData['elError'].values
        az_rms = np.sqrt(np.mean(az_vals * az_vals))
        el_rms = np.sqrt(np.mean(el_vals * el_vals))

        # Calculate Image impact RMS
        # We are less sensitive to Az errors near the zenith
        image_az_rms = az_rms * np.cos(el_vals[0] * np.pi / 180.0)
        image_el_rms = el_rms 

        ax1p5.plot(azimuthData['azError'], label='Azimuth error', c=lineColors[colorCounter])
        colorCounter += 1
        ax1p5.plot(elevationData['elError'], label='Elevation error', c=lineColors[colorCounter])
        colorCounter += 1
        ax1p5.yaxis.set_major_formatter(FuncFormatter(tickFormatter))
        ax1p5.set_ylabel('Tracking error (arcsec)')
        ax1p5.set_xticks([])  # remove x tick labels on the hidden upper x-axis
        ax1p5.set_ylim(-0.5, 0.5)
        ax1p5.set_yticks([-0.25, 0.0, 0.25])
        ax1p5.legend()
        ax1p5.text(0.2, 0.9, \
                   f'Az image RMS = {image_az_rms:.3f} arsec,   El image RMS = {image_el_rms:.3f} arsec',\
                   transform=ax1p5.transAxes)

    if prePadding or postPadding:
        # note the conversion to utc because the x-axis from the dataframe
        # already got automagically converted when plotting before, so this is
        # necessary for things to line up
        ax1_twin.axvline(event.begin.utc.datetime, c='k', ls='--', alpha=0.5, label='Event begin/end')
        ax1_twin.axvline(event.end.utc.datetime, c='k', ls='--', alpha=0.5)
        # extend lines down across lower plot, but do not re-add label
        ax2_twin.axvline(event.begin.utc.datetime, c='k', ls='--', alpha=0.5)
        ax2_twin.axvline(event.end.utc.datetime, c='k', ls='--', alpha=0.5)

    for command, commandTime in commands.items():
        # if commands weren't found, the item is set to None. This is common
        # for events so handle it gracefully and silently. The command finding
        # code logs about lack of commands found so no need to mention here.
        if commandTime is None:
            continue
        ax1_twin.axvline(commandTime.utc.datetime, c=lineColors[colorCounter],
                         ls='--', alpha=0.75, label=f'{command}')
        # extend lines down across lower plot, but do not re-add label
        ax2_twin.axvline(commandTime.utc.datetime, c=lineColors[colorCounter],
                         ls='--', alpha=0.75)
        colorCounter += 1

    # combine the legends and put inside the plot
    handles1a, labels1a = ax1.get_legend_handles_labels()
    handles1b, labels1b = ax1_twin.get_legend_handles_labels()
    handles2a, labels2a = ax2.get_legend_handles_labels()
    handles2b, labels2b = ax2_twin.get_legend_handles_labels()

    handles = handles1a + handles1b + handles2a + handles2b
    labels = labels1a + labels1b + labels2a + labels2b
    # ax2 is "in front" of ax1 because it has the vlines plotted on it, and
    # vlines are on ax2 so that they appear at the bottom of the legend, so
    # make sure to plot the legend on ax2, otherwise the vlines will go on top
    # of the otherwise-opaque legend.
    ax1_twin.legend(handles, labels, facecolor='white', framealpha=1)

    # Add title with the event name, type etc
    dayObsStr = dayObsIntToString(event.dayObs)
    title = (f"{dayObsStr} - seqNum {event.seqNum} (version {event.version})"  # top line, rest below
             f"\nDuration = {event.duration:.2f}s"
             f" Event type: {event.type.name}"
             f" End reason: {event.endReason.name}"
             )
    ax1_twin.set_title(title)
    return fig


def getCommandsDuringEvent(client, event, commands=('raDecTarget'), log=None, doLog=True):
    """Get the commands issued during an event.

    Get the times at which the specified commands were issued during the event.

    Parameters
    ----------
    client : `lsst_efd_client.efd_helper.EfdClient`
        The EFD client to use.
    event : `lsst.summit.utils.tmaUtils.TMAEvent`
        The event to plot.
    commands : `list` of `str`, optional
        The commands or command aliases to look for. Defaults to
        ['raDecTarget'].
    log : `logging.Logger`, optional
        The logger to use. If not specified, a new logger will be created if
        needed.
    doLog : `bool`, optional
        Whether to log messages. Defaults to True.

    Returns
    -------
    commands : `dict` of `str` : `astropy.time.Time`
        A dictionary of the commands and the times at which they were issued.
    """
    # TODO: DM-40100 Add support for padding the event here to allow looking
    # for triggering commands before the event

    # TODO: DM-40100 Change this to always return a list of times, and remove
    # warning about finding multiple commands. Remember to update docs and
    # plotting code.
    if log is None and doLog:
        log = logging.getLogger(__name__)

    commands = ensure_iterable(commands)
    fullCommands = [c if c not in COMMAND_ALIASES else COMMAND_ALIASES[c] for c in commands]
    del commands  # make sure we always use their full names

    ret = {}
    for command in fullCommands:
        data = getEfdData(client, command, event=event, warn=False)
        if data.empty:
            if doLog:
                log.info(f'Found no command issued for {command} during event')
            ret[command] = None
        elif len(data) > 1:
            if doLog:
                log.warning(f'Found multiple commands issued for {command} during event, returning None')
            ret[command] = None
        else:
            assert len(data) == 1  # this must be true now
            commandTime = data.private_efdStamp
            ret[command] = Time(commandTime, format='unix')

    return ret


def _initializeTma(tma):
    """Helper function to turn a TMA into a valid state for testing.

    Do not call directly in normal usage or code, as this just arbitrarily
    sets values to make the TMA valid.

    Parameters
    ----------
    tma : `lsst.summit.utils.tmaUtils.TMAStateMachine`
        The TMA state machine model to initialize.
    """
    tma._parts['azimuthInPosition'] = False
    tma._parts['azimuthMotionState'] = AxisMotionState.STOPPED
    tma._parts['azimuthSystemState'] = PowerState.ON
    tma._parts['elevationInPosition'] = False
    tma._parts['elevationMotionState'] = AxisMotionState.STOPPED
    tma._parts['elevationSystemState'] = PowerState.ON


@dataclass(kw_only=True, frozen=True)
class TMAEvent:
    """A movement event for the TMA.

    Contains the dayObs on which the event occured, using the standard
    observatory definition of the dayObs, and the sequence number of the event,
    which is unique for each event on a given dayObs.

    The event type can be either 'SLEWING' or 'TRACKING', defined as:
        - SLEWING: some part of the TMA is in motion
        - TRACKING: both axes are in position and tracking the sky

    The end reason can be 'STOPPED', 'TRACKING', 'FAULT', 'SLEWING', or 'OFF'.
        - SLEWING: The previous event was a TRACKING event, and one or more of
            the TMA components either stopped being in position, or stopped
            moving, or went into fault, or was turned off, and hence we are now
            only slewing and no longer tracking the sky.
        - TRACKING: the TMA started tracking the sky when it wasn't previously.
            Usualy this would always be preceded by directly by a SLEWING
            event, but this is not strictly true, as the EUI seems to be able
            to make the TMA start tracking the sky without slewing first.
        - STOPPED: the components of the TMA transitioned to the STOPPED state.
        - FAULT: the TMA went into fault.
        - OFF: the TMA components were turned off.

    Note that this class is not intended to be instantiated directly, but
    rather to be returned by the ``TMAEventMaker.getEvents()`` function.

    Parameters
    ----------
    dayObs : `int`
        The dayObs on which the event occured.
    seqNum : `int`
        The sequence number of the event,
    type : `lsst.summit.utils.tmaUtils.TMAState`
        The type of the event, either 'SLEWING' or 'TRACKING'.
    endReason : `lsst.summit.utils.tmaUtils.TMAState`
        The reason the event ended, either 'STOPPED', 'TRACKING', 'FAULT',
        'SLEWING', or 'OFF'.
    duration : `float`
        The duration of the event, in seconds.
    begin : `astropy.time.Time`
        The time the event began.
    end : `astropy.time.Time`
        The time the event ended.
    blockInfos : `list` of `lsst.summit.utils.tmaUtils.BlockInfo`, or `None`
        The block infomation, if any, relating to the event. Could be `None`,
        or one or more block informations.
    version : `int`
        The version of the TMAEvent class. Equality between events is only
        valid for a given version of the class. If the class definition
        changes, the time ranges can change, and hence the equality between
        events is ``False``.
    _startRow : `int`
        The first row in the merged EFD data which is part of the event.
    _endRow : `int`
        The last row in the merged EFD data which is part of the event.
    """
    dayObs: int
    seqNum: int
    type: str  # can be 'SLEWING', 'TRACKING'
    endReason: str  # can be 'STOPPED', 'TRACKING', 'FAULT', 'SLEWING', 'OFF'
    duration: float  # seconds
    begin: Time
    end: Time
    blockInfos: list = field(default_factory=list)
    version: int = 0  # update this number any time a code change which could change event definitions is made
    _startRow: int
    _endRow: int

    def __lt__(self, other):
        if self.version != other.version:
            raise ValueError(
                f"Cannot compare TMAEvents with different versions: {self.version} != {other.version}"
            )
        if self.dayObs < other.dayObs:
            return True
        elif self.dayObs == other.dayObs:
            return self.seqNum < other.seqNum
        return False

    def __repr__(self):
        return (
            f"TMAEvent(dayObs={self.dayObs}, seqNum={self.seqNum}, type={self.type!r},"
            f" endReason={self.endReason!r}, duration={self.duration}, begin={self.begin!r},"
            f" end={self.end!r}"
        )

    def __hash__(self):
        # deliberately don't hash the blockInfos here, as they are not
        # a core part of the event itself, and are listy and cause problems
        return hash((self.dayObs,
                     self.seqNum,
                     self.type,
                     self.endReason,
                     self.duration,
                     self.begin,
                     self.end,
                     self.version,
                     self._startRow,
                     self._endRow
                     )
                    )

    def _ipython_display_(self):
        print(self.__str__())

    def __str__(self):
        def indent(string):
            return '\n' + '\n'.join(['    ' + s for s in string.splitlines()])

        blockInfoStr = 'None'
        if self.blockInfos is not None:
            blockInfoStr = ''.join(indent(str(i)) for i in self.blockInfos)

        return (
            f"dayObs: {self.dayObs}\n"
            f"seqNum: {self.seqNum}\n"
            f"type: {self.type.name}\n"
            f"endReason: {self.endReason.name}\n"
            f"duration: {self.duration}\n"
            f"begin: {self.begin!r}\n"
            f"end: {self.end!r}\n"
            f"blockInfos: {blockInfoStr}"
        )

    def associatedWith(self, block=None, blockSeqNum=None, ticket=None, salIndex=None):
        """Check whether an event is associated with a set of parameters.

        Check if an event is associated with a specific block and/or ticket
        and/or salIndex. All specified parameters must match for the function
        to return True. If checking if an event is in a block, the blockSeqNum
        can also be specified to identify events which related to a given
        running the specified block.

        Parameters
        ----------
        block : `int`, optional
            The block number to check for.
        blockSeqNum : `int`, optional
            The block sequence number to check for, if the block is specified.
        ticket : `str`, optional
            The ticket number to check for.
        salIndex : `int`, optional
            The salIndex to check for.

        Returns
        -------
        relates : `bool`
            Whether the event is associated with the specified block, ticket,
            and salIndex.
        """
        if all([block is None, ticket is None, salIndex is None]):
            raise ValueError('Must specify at least one of block, ticket, or salIndex')

        if blockSeqNum is not None and block is None:
            raise ValueError('block must be specified if blockSeqNum is specified')

        for blockInfo in self.blockInfos:
            # "X is None or" is used for each parameter to allow it to be None
            # in the kwargs
            blockMatches = False
            if block is not None:
                if blockSeqNum is None and blockInfo.blockNumber == block:
                    blockMatches = True
                elif (blockSeqNum is not None and
                      blockInfo.blockNumber == block and
                      blockInfo.seqNum == blockSeqNum):
                    blockMatches = True
            else:
                blockMatches = True  # no block specified at all, so it matches

            salIndexMatches = (salIndex is None or salIndex in blockInfo.salIndices)
            ticketMatches = (ticket is None or ticket in blockInfo.tickets)

            if blockMatches and salIndexMatches and ticketMatches:
                return True

        return False


class TMAState(enum.IntEnum):
    """Overall state of the TMA.

    States are defined as follows:

    UNINITIALIZED
        We have not yet got data for all relevant components, so the overall
        state is undefined.
    STOPPED
        All components are on, and none are moving.
    TRACKING
        We are tracking the sky.
    SLEWING
        One or more components are moving, and one or more are not tracking the
        sky. This should probably be called MOVING, as it includes: slewing,
        MOVING_POINT_TO_POINT, and JOGGING.
    FAULT
        All (if engineeringMode) or any (if not engineeringMode) components are
        in fault.
    OFF
        All components are off.
    """
    UNINITIALIZED = -1
    STOPPED = 0
    TRACKING = 1
    SLEWING = 2
    FAULT = 3
    OFF = 4

    def __repr__(self):
        return f"TMAState.{self.name}"


def getAxisAndType(rowFor):
    """Get the axis the data relates to, and the type of data it contains.

    Parameters
    ----------
    rowFor : `str`
        The column in the dataframe denoting what this row is for, e.g.
            "elevationMotionState" or "azimuthInPosition", etc.

    Returns
    -------
    axis : `str`
        The axis the row is for, e.g. "azimuth", "elevation".
    rowType : `str`
        The type of the row, e.g. "MotionState", "SystemState", "InPosition".
    """
    regex = r'(azimuth|elevation)(InPosition|MotionState|SystemState)$'  # matches the end of the line
    matches = re.search(regex, rowFor)
    if matches is None:
        raise ValueError(f"Could not parse axis and rowType from {rowFor=}")
    axis = matches.group(1)
    rowType = matches.group(2)

    assert rowFor.endswith(f"{axis}{rowType}")
    return axis, rowType


class ListViewOfDict:
    """A class to allow making lists which contain references to an underlying
    dictionary.

    Normally, making a list of items from a dictionary would make a copy of the
    items, but this class allows making a list which contains references to the
    underlying dictionary items themselves. This is useful for making a list of
    components, such that they can be manipulated in their logical sets.
    """
    def __init__(self, underlyingDictionary, keysToLink):
        self.dictionary = underlyingDictionary
        self.keys = keysToLink

    def __getitem__(self, index):
        return self.dictionary[self.keys[index]]

    def __setitem__(self, index, value):
        self.dictionary[self.keys[index]] = value

    def __len__(self):
        return len(self.keys)


class TMAStateMachine:
    """A state machine model of the TMA.

    Note that this is currently only implemented for the azimuth and elevation
    axes, but will be extended to include the rotator in the future.

    Note that when used for event generation, changing ``engineeringMode`` to
    False might change the resulting list of events, and that if the TMA moves
    with some axis in fault, then these events will be missed. It is therefore
    thought that ``engineeringMode=True`` should always be used when generating
    events. The option, however, is there for completeness, as this will be
    useful for knowing is the CSC would consider the TMA to be in fault in the
    general case.

    Parameters
    ----------
    engineeringMode : `bool`, optional
        Whether the TMA is in engineering mode. Defaults to True. If False,
        then the TMA will be in fault if any component is in fault. If True,
        then the TMA will be in fault only if all components are in fault.
    debug : `bool`, optional
        Whether to log debug messages. Defaults to False.
    """
    _UNINITIALIZED_VALUE: int = -999

    def __init__(self, engineeringMode=True, debug=False):
        self.engineeringMode = engineeringMode
        self.log = logging.getLogger('lsst.summit.utils.tmaUtils.TMA')
        if debug:
            self.log.level = logging.DEBUG
        self._mostRecentRowTime = -1

        # the actual components of the TMA
        self._parts = {'azimuthInPosition': self._UNINITIALIZED_VALUE,
                       'azimuthMotionState': self._UNINITIALIZED_VALUE,
                       'azimuthSystemState': self._UNINITIALIZED_VALUE,
                       'elevationInPosition': self._UNINITIALIZED_VALUE,
                       'elevationMotionState': self._UNINITIALIZED_VALUE,
                       'elevationSystemState': self._UNINITIALIZED_VALUE,
                       }
        systemKeys = ['azimuthSystemState', 'elevationSystemState']
        positionKeys = ['azimuthInPosition', 'elevationInPosition']
        motionKeys = ['azimuthMotionState', 'elevationMotionState']

        # references to the _parts as conceptual groupings
        self.system = ListViewOfDict(self._parts, systemKeys)
        self.motion = ListViewOfDict(self._parts, motionKeys)
        self.inPosition = ListViewOfDict(self._parts, positionKeys)

        # tuples of states for state collapsing. Note that STOP_LIKE +
        # MOVING_LIKE must cover the full set of AxisMotionState enums
        self.STOP_LIKE = (AxisMotionState.STOPPING,
                          AxisMotionState.STOPPED,
                          AxisMotionState.TRACKING_PAUSED)
        self.MOVING_LIKE = (AxisMotionState.MOVING_POINT_TO_POINT,
                            AxisMotionState.JOGGING,
                            AxisMotionState.TRACKING)
        # Likewise, ON_LIKE + OFF_LIKE must cover the full set of PowerState
        # enums
        self.OFF_LIKE = (PowerState.OFF, PowerState.TURNING_OFF)
        self.ON_LIKE = (PowerState.ON, PowerState.TURNING_ON)
        self.FAULT_LIKE = (PowerState.FAULT,)  # note the trailing comma - this must be an iterable

    def apply(self, row):
        """Apply a row of data to the TMA state.

        Checks that the row contains data for a later time than any data
        previously applied, and applies the relevant column entry to the
        relevant component.

        Parameters
        ----------
        row : `pd.Series`
            The row of data to apply to the state machine.
        """
        timestamp = row['private_efdStamp']
        if timestamp < self._mostRecentRowTime:  # NB equals is OK, technically, though it never happens
            raise ValueError('TMA evolution must be monotonic increasing in time, tried to apply a row which'
                             ' predates the most previous one')
        self._mostRecentRowTime = timestamp

        rowFor = row['rowFor']  # e.g. elevationMotionState
        axis, rowType = getAxisAndType(rowFor)  # e.g. elevation, MotionState
        value = self._getRowPayload(row, rowType, rowFor)
        self.log.debug(f"Setting {rowFor} to {repr(value)}")
        self._parts[rowFor] = value
        try:
            # touch the state property as this executes the sieving, to make
            # sure we don't fall through the sieve at any point in time
            _ = self.state
        except RuntimeError as e:
            # improve error reporting, but always reraise this, as this is a
            # full-blown failure
            raise RuntimeError(f'Failed to apply {value} to {axis}{rowType} with state {self._parts}') from e

    def _getRowPayload(self, row, rowType, rowFor):
        """Get the relevant value from the row.

        Given the row, and which component it relates to, get the relevant
        value, as a bool or cast to the appropriate enum class.

        Parameters
        ----------
        row : `pd.Series`
            The row of data from the dataframe.
        rowType : `str`
            The type of the row, e.g. "MotionState", "SystemState",
            "InPosition".
        rowFor : `str`
            The component the row is for, e.g. "azimuth", "elevation".

        Returns
        -------
        value : `bool` or `enum`
            The value of the row, as a bool or enum, depending on the
            component, cast to the appropriate enum class or bool.
        """
        match rowType:
            case 'MotionState':
                value = row[f'state_{rowFor}']
                return AxisMotionState(value)
            case 'SystemState':
                value = row[f'powerState_{rowFor}']
                return PowerState(value)
            case 'InPosition':
                value = row[f'inPosition_{rowFor}']
                return bool(value)
            case _:
                raise ValueError(f'Failed to get row payload with {rowType=} and {row=}')

    @property
    def _isValid(self):
        """Has the TMA had a value applied to all its components?

        If any component has not yet had a value applied, the TMA is not valid,
        as those components will be in an unknown state.

        Returns
        -------
        isValid : `bool`
            Whether the TMA is fully initialized.
        """
        return not any([v == self._UNINITIALIZED_VALUE for v in self._parts.values()])

    # state inspection properties - a high level way of inspecting the state as
    # an API
    @property
    def isMoving(self):
        return self.state in [TMAState.TRACKING, TMAState.SLEWING]

    @property
    def isNotMoving(self):
        return not self.isMoving

    @property
    def isTracking(self):
        return self.state == TMAState.TRACKING

    @property
    def isSlewing(self):
        return self.state == TMAState.SLEWING

    @property
    def canMove(self):
        badStates = [PowerState.OFF, PowerState.TURNING_OFF, PowerState.FAULT, PowerState.UNKNOWN]
        return bool(
            self._isValid and
            self._parts['azimuthSystemState'] not in badStates and
            self._parts['elevationSystemState'] not in badStates
        )

    # Axis inspection properties, designed for internal use. These return
    # iterables so that they can be used in any() and all() calls, which make
    # the logic much easier to read, e.g. to see if anything is moving, we can
    # write `if not any(_axisInMotion):`
    @property
    def _axesInFault(self):
        return [x in self.FAULT_LIKE for x in self.system]

    @property
    def _axesOff(self):
        return [x in self.OFF_LIKE for x in self.system]

    @property
    def _axesOn(self):
        return [not x for x in self._axesOn]

    @property
    def _axesInMotion(self):
        return [x in self.MOVING_LIKE for x in self.motion]

    @property
    def _axesTRACKING(self):
        """Note this is deliberately named _axesTRACKING and not _axesTracking
        to make it clear that this is the AxisMotionState type of TRACKING and
        not the normal conceptual notion of tracking (the sky, i.e. as opposed
        to slewing).
        """
        return [x == AxisMotionState.TRACKING for x in self.motion]

    @property
    def _axesInPosition(self):
        return [x is True for x in self.inPosition]

    @property
    def state(self):
        """The overall state of the TMA.

        Note that this is both a property, and also the method which applies
        the logic sieve to determine the state at a given point in time.

        Returns
        -------
        state : `lsst.summit.utils.tmaUtils.TMAState`
            The overall state of the TMA.
        """
        # first, check we're valid, and if not, return UNINITIALIZED state, as
        # things are unknown
        if not self._isValid:
            return TMAState.UNINITIALIZED

        # if we're not in engineering mode, i.e. we're under normal CSC
        # control, then if anything is in fault, we're in fault. If we're
        # engineering then some axes will move when others are in fault
        if not self.engineeringMode:
            if any(self._axesInFault):
                return TMAState.FAULT
        else:
            # we're in engineering mode, so return fault state if ALL are in
            # fault
            if all(self._axesInFault):
                return TMAState.FAULT

        # if all axes are off, the TMA is OFF
        if all(self._axesOff):
            return TMAState.OFF

        # we know we're valid and at least some axes are not off, so see if
        # we're in motion if no axes are moving, we're stopped
        if not any(self._axesInMotion):
            return TMAState.STOPPED

        # now we know we're initialized, and that at least one axis is moving
        # so check axes for motion and in position. If all axes are tracking
        # and all are in position, we're tracking the sky
        if (all(self._axesTRACKING) and all(self._axesInPosition)):
            return TMAState.TRACKING

        # we now know explicitly that not everything is in position, so we no
        # longer need to check that. We do actually know that something is in
        # motion, but confirm that's the case and return SLEWING
        if (any(self._axesInMotion)):
            return TMAState.SLEWING

        # if we want to differentiate between MOVING_POINT_TO_POINT moves,
        # JOGGING moves and regular slews, the logic in the step above needs to
        # be changed and the new steps added here.

        raise RuntimeError('State error: fell through the state sieve - rewrite your logic!')


class TMAEventMaker:
    """A class to create per-dayObs TMAEvents for the TMA's movements.

    If this class is being used in tests, make sure to pass the EFD client in,
    and create it with `makeEfdClient(testing=True)`. This ensures that the
    USDF EFD is "used" as this is the EFD which has the recorded data available
    in the test suite via `vcr`.

    Example usage:
    >>> dayObs = 20230630
    >>> eventMaker = TMAEventMaker()
    >>> events = eventMaker.getEvents(dayObs)
    >>> print(f'Found {len(events)} for {dayObs=}')

    Parameters
    ----------
    client : `lsst_efd_client.efd_helper.EfdClient`, optional
        The EFD client to use, created if not provided.
    """
    # the topics which need logical combination to determine the overall mount
    # state. Will need updating as new components are added to the system.

    # relevant column: 'state'
    _movingComponents = [
        'lsst.sal.MTMount.logevent_azimuthMotionState',
        'lsst.sal.MTMount.logevent_elevationMotionState',
    ]

    # relevant column: 'inPosition'
    _inPositionComponents = [
        'lsst.sal.MTMount.logevent_azimuthInPosition',
        'lsst.sal.MTMount.logevent_elevationInPosition',
    ]

    # the components which, if in fault, put the TMA into fault
    # relevant column: 'powerState'
    _stateComponents = [
        'lsst.sal.MTMount.logevent_azimuthSystemState',
        'lsst.sal.MTMount.logevent_elevationSystemState',
    ]

    def __init__(self, client=None):
        if client is not None:
            self.client = client
        else:
            self.client = makeEfdClient()
        self.log = logging.getLogger(__name__)
        self._data = {}

    @dataclass(frozen=True)
    class ParsedState:
        eventStart: Time
        eventEnd: int
        previousState: TMAState
        state: TMAState

    @staticmethod
    def isToday(dayObs):
        """Find out if the specified dayObs is today, or in the past.

        If the day is today, the function returns ``True``, if it is in the
        past it returns ``False``. If the day is in the future, a
        ``ValueError`` is raised, as this indicates there is likely an
        off-by-one type error somewhere in the logic.

        Parameters
        ----------
        dayObs : `int`
            The dayObs to check, in the format YYYYMMDD.

        Returns
        -------
        isToday : `bool`
            ``True`` if the dayObs is today, ``False`` if it is in the past.

        Raises
            ValueError: if the dayObs is in the future.
        """
        todayDayObs = getCurrentDayObs_int()
        if dayObs == todayDayObs:
            return True
        if dayObs > todayDayObs:
            raise ValueError("dayObs is in the future")
        return False

    @staticmethod
    def _shortName(topic):
        """Get the short name of a topic.

        Parameters
        ----------
        topic : `str`
            The topic to get the short name of.

        Returns
        -------
        shortName : `str`
            The short name of the topic, e.g. 'azimuthInPosition'
        """
        # get, for example 'azimuthInPosition' from
        # lsst.sal.MTMount.logevent_azimuthInPosition
        return topic.split('_')[-1]

    def _mergeData(self, data):
        """Merge a dict of dataframes based on private_efdStamp, recording
        where each row came from.

        Given a dict or dataframes, keyed by topic, merge them into a single
        dataframe, adding a column to record which topic each row came from.

        Parameters
        ----------
        data : `dict` of `str` : `pd.DataFrame`
            The dataframes to merge.

        Returns
        -------
        merged : `pd.DataFrame`
            The merged dataframe.
        """
        excludeColumns = ['private_efdStamp', 'rowFor']

        mergeArgs = {
            'how': 'outer',
            'sort': True,
        }

        merged = None
        originalRowCounter = 0

        # Iterate over the keys and merge the corresponding DataFrames
        for key, df in data.items():
            if df.empty:
                # Must skip the df if it's empty, otherwise the merge will fail
                # due to lack of private_efdStamp. Because other axes might
                # still be in motion, so we still want to merge what we have
                continue

            originalRowCounter += len(df)
            component = self._shortName(key)  # Add suffix to column names to identify the source
            suffix = '_' + component

            df['rowFor'] = component

            columnsToSuffix = [col for col in df.columns if col not in excludeColumns]
            df_to_suffix = df[columnsToSuffix].add_suffix(suffix)
            df = pd.concat([df[excludeColumns], df_to_suffix], axis=1)

            if merged is None:
                merged = df.copy()
            else:
                merged = pd.merge(merged, df, **mergeArgs)

        merged = merged.loc[:, ~merged.columns.duplicated()]  # Remove duplicate columns after merge

        if len(merged) != originalRowCounter:
            self.log.warning("Merged data has a different number of rows to the original data, some"
                             " timestamps (rows) will contain more than one piece of actual information.")

        # if the index is still a DatetimeIndex here then we didn't actually
        # merge any data, so there is only data from a single component.
        # This is likely to result in no events, but not necessarily, and for
        # generality, instead we convert to a range index to ensure consistency
        # in the returned data, and allow processing to continue.
        if isinstance(merged.index, pd.DatetimeIndex):
            self.log.warning("Data was only found for a single component in the EFD.")
            merged.reset_index(drop=True, inplace=True)

        return merged

    def getEvent(self, dayObs, seqNum):
        """Get a specific event for a given dayObs and seqNum.

        Repeated calls for the same ``dayObs`` will use the cached data if the
        day is in the past, and so will be much quicker. If the ``dayObs`` is
        the current day then the EFD will be queried for new data for each
        call, so a call which returns ``None`` on the first try might return an
        event on the next, if the TMA is still moving and thus generating
        events.

        Parameters
        ----------
        dayObs : `int`
            The dayObs to get the event for.
        seqNum : `int`
            The sequence number of the event to get.

        Returns
        -------
        event : `lsst.summit.utils.tmaUtils.TMAEvent`
            The event for the specified dayObs and seqNum, or `None` if the
            event was not found.
        """
        events = self.getEvents(dayObs)
        if seqNum <= len(events):
            event = events[seqNum]
            if event.seqNum != seqNum:
                # it's zero-indexed and contiguous so this must be true but
                # a sanity check doesn't hurt.
                raise AssertionError(f"Event sequence number mismatch: {event.seqNum} != {seqNum}")
            return event
        else:
            self.log.warning(f"Event {seqNum} not found for {dayObs}")
            return None

    def getEvents(self, dayObs):
        """Get the TMA events for the specified dayObs.

        Gets the required mount data from the cache or the EFD as required,
        handling whether we're working with live vs historical data. The
        dataframes from the EFD is merged and applied to the TMAStateMachine,
        and that series of state changes is used to generate a list of
        TmaEvents for the day's data.

        If the data is for the current day, i.e. if new events can potentially
        land, then if the last event is "open" (meaning that the TMA appears to
        be in motion and thus the event is growing with time), then that event
        is excluded from the event list as it is expected to be changing with
        time, and will likely close eventually. However, if that situation
        occurs on a day in the past, then that event can never close, and the
        event is therefore included, but a warning about the open event is
        logged.

        Parameters
        ----------
        dayObs : `int`
            The dayObs for which to get the events.

        Returns
        -------
        events : `list` of `lsst.summit.utils.tmaUtils.TMAState`
            The events for the specified dayObs.
        """
        workingLive = self.isToday(dayObs)
        data = None

        if workingLive:
            # it's potentially updating data, so we must update the date
            # regarless of whether we have it already or not
            self.log.info(f'Updating mount data for {dayObs} from the EFD')
            self._getEfdDataForDayObs(dayObs)
            data = self._data[dayObs]
        elif dayObs in self._data:
            # data is in the cache and it's not being updated, so use it
            data = self._data[dayObs]
        elif dayObs not in self._data:
            # we don't have the data yet, but it's not growing, so put it in
            # the cache and use it from there
            self.log.info(f'Retrieving mount data for {dayObs} from the EFD')
            self._getEfdDataForDayObs(dayObs)
            data = self._data[dayObs]
        else:
            raise RuntimeError("This should never happen")

        # if we don't have something to work with, log a warning and return
        if not self.dataFound(data):
            self.log.warning(f"No EFD data found for {dayObs=}")
            return []

        # applies the data to the state machine, and generates events from the
        # series of states which results
        events = self._calculateEventsFromMergedData(data, dayObs, dataIsForCurrentDay=workingLive)
        if not events:
            self.log.warning(f"Failed to calculate any events for {dayObs=} despite EFD data existing!")
        return events

    @staticmethod
    def dataFound(data):
        """Check if any data was found.

        Parameters
        ----------
        data : `pd.DataFrame`
            The merged dataframe to check.

        Returns
        -------
        dataFound : `bool`
            Whether data was found.
        """
        # You can't just compare to with data == NO_DATA_SENTINEL because
        # `data` is usually a dataframe, and you can't compare a dataframe to a
        # string directly.
        return not (isinstance(data, str) and data == NO_DATA_SENTINEL)

    def _getEfdDataForDayObs(self, dayObs):
        """Get the EFD data for the specified dayObs and store it in the cache.

        Gets the EFD data for all components, as a dict of dataframes keyed by
        component name. These are then merged into a single dataframe in time
        order, based on each row's `private_efdStamp`. This is then stored in
        self._data[dayObs].

        If no data is found, the value is set to ``NO_DATA_SENTINEL`` to
        differentiate this from ``None``, as this is what you'd get if you
        queried the cache with `self._data.get(dayObs)`. It also marks that we
        have already queried this day.

        Parameters
        ----------
        dayObs : `int`
            The dayObs to query.
        """
        data = {}
        for component in itertools.chain(
            self._movingComponents,
            self._inPositionComponents,
            self._stateComponents
        ):
            data[component] = getEfdData(self.client, component, dayObs=dayObs, warn=False)
            self.log.debug(f"Found {len(data[component])} for {component}")

        if all(dataframe.empty for dataframe in data.values()):
            # if every single dataframe is empty, set the sentinel and don't
            # try to merge anything, otherwise merge all the data we found
            self.log.debug(f"No data found for {dayObs=}")
            # a sentinel value that's not None
            self._data[dayObs] = NO_DATA_SENTINEL
        else:
            merged = self._mergeData(data)
            self._data[dayObs] = merged

    def _calculateEventsFromMergedData(self, data, dayObs, dataIsForCurrentDay):
        """Calculate the list of events from the merged data.

        Runs the merged data, row by row, through the TMA state machine (with
        ``tma.apply``) to get the overall TMA state at each row, building a
        dict of these states, keyed by row number.

        This time-series of TMA states are then looped over (in
        `_statesToEventTuples`), building a list of tuples representing the
        start and end of each event, the type of the event, and the reason for
        the event ending.

        This list of tuples is then passed to ``_makeEventsFromStateTuples``,
        which actually creates the ``TMAEvent`` objects.

        Parameters
        ----------
        data : `pd.DataFrame`
            The merged dataframe to use.
        dayObs : `int`
            The dayObs for the data.
        dataIsForCurrentDay : `bool`
            Whether the data is for the current day. Determines whether to
            allow an open last event or not.

        Returns
        -------
        events : `list` of `lsst.summit.utils.tmaUtils.TMAEvent`
            The events for the specified dayObs.
        """
        engineeringMode = True
        tma = TMAStateMachine(engineeringMode=engineeringMode)

        # For now, we assume that the TMA starts each day able to move, but
        # stationary. If this turns out to cause problems, we will need to
        # change to loading data from the previous day(s), and looking back
        # through it in time until a state change has been found for every
        # axis. For now though, Bruno et. al think this is acceptable and
        # preferable.
        _initializeTma(tma)

        tmaStates = {}
        for rowNum, row in data.iterrows():
            tma.apply(row)
            tmaStates[rowNum] = tma.state

        stateTuples = self._statesToEventTuples(tmaStates, dataIsForCurrentDay)
        events = self._makeEventsFromStateTuples(stateTuples, dayObs, data)
        self.addBlockDataToEvents(dayObs, events)
        return events

    def _statesToEventTuples(self, states, dataIsForCurrentDay):
        """Get the event-tuples from the dictionary of TMAStates.

        Chunks the states into blocks of the same state, so that we can create
        an event for each block in `_makeEventsFromStateTuples`. Off-type
        states are skipped over, with each event starting when the telescope
        next resumes motion or changes to a different type of motion state,
        i.e. from non-tracking type movement (MOVE_POINT_TO_POINT, JOGGING,
        TRACKING-but-not-in-position, i.e. slewing) to a tracking type
        movement, or vice versa.

        Parameters
        ----------
        states : `dict` of `int` : `lsst.summit.utils.tmaUtils.TMAState`
            The states of the TMA, keyed by row number.
        dataIsForCurrentDay : `bool`
            Whether the data is for the current day. Determines whether to
            allow and open last event or not.

        Returns
        -------
        parsedStates : `list` of `tuple`
            The parsed states, as a list of tuples of the form:
                ``(eventStart, eventEnd, eventType, endReason)``
        """
        # Consider rewriting this with states as a list and using pop(0)?
        skipStates = (TMAState.STOPPED, TMAState.OFF, TMAState.FAULT)

        parsedStates = []
        eventStart = None
        rowNum = 0
        nRows = len(states)
        while rowNum < nRows:
            previousState = None
            state = states[rowNum]
            # if we're not in an event, fast forward through off-like rows
            # until a new event starts
            if eventStart is None and state in skipStates:
                rowNum += 1
                continue

            # we've started a new event, so walk through it and find the end
            eventStart = rowNum
            previousState = state
            rowNum += 1  # move to the next row before starting the while loop
            if rowNum == nRows:
                # we've reached the end of the data, and we're still in an
                # event, so don't return this presumably in-progress event
                self.log.warning('Reached the end of the data while starting a new event')
                break
            state = states[rowNum]
            while state == previousState:
                rowNum += 1
                if rowNum == nRows:
                    break
                state = states[rowNum]
            parsedStates.append(
                self.ParsedState(
                    eventStart=eventStart,
                    eventEnd=rowNum,
                    previousState=previousState,
                    state=state
                )
            )
            if state in skipStates:
                eventStart = None

        # done parsing, just check the last event is valid
        if parsedStates:  # ensure we have at least one event
            lastEvent = parsedStates[-1]
            if lastEvent.eventEnd == nRows:
                # Generally, you *want* the timespan for an event to be the
                # first row of the next event, because you were in that state
                # right up until that state change. However, if that event is
                # a) the last one of the day and b) runs right up until the end
                # of the dataframe, then there isn't another row, so this will
                # overrun the array.
                #
                # If the data is for the current day then this isn't a worry,
                # as we're likely still taking data, and this event will likely
                # close yet, so we don't issue a warning, and simply drop the
                # event from the list.

                # However, if the data is for a past day then no new data will
                # come to close the event, so allow the event to be "open", and
                # issue a warning
                if dataIsForCurrentDay:
                    self.log.info("Discarding open (likely in-progess) final event from current day's events")
                    parsedStates = parsedStates[:-1]
                else:
                    self.log.warning("Last event ends open, forcing it to end at end of the day's data")
                    # it's a tuple, so (deliberately) awkward to modify
                    parsedStates[-1] = self.ParsedState(
                        eventStart=lastEvent.eventStart,
                        eventEnd=lastEvent.eventEnd - 1,
                        previousState=lastEvent.previousState,
                        state=lastEvent.state
                    )

        return parsedStates

    def addBlockDataToEvents(self, dayObs, events):
        """Find all the block data in the EFD for the specified events.

        Finds all the block data in the EFD relating to the events, parses it,
        from the rows of the dataframe, and adds it to the events in place.

        Parameters
        ----------
        events : `lsst.summit.utils.tmaUtils.TMAEvent` or
                 `list` of `lsst.summit.utils.tmaUtils.TMAEvent`
            One or more events to get the block data for.
        """
        try:
            blockParser = BlockParser(dayObs, client=self.client)
        except Exception as e:
            # adding the block data should never cause a failure so if we can't
            # get the block data, log a warning and return. It is, however,
            # never expected, so use log.exception to get the full traceback
            # and scare users so it gets reported
            self.log.exception(f'Failed to parse block data for {dayObs=}, {e}')
            return
        blocks = blockParser.getBlockNums()
        blockDict = {}
        for block in blocks:
            blockDict[block] = blockParser.getSeqNums(block)

        for block, seqNums in blockDict.items():
            for seqNum in seqNums:
                blockInfo = blockParser.getBlockInfo(block=block, seqNum=seqNum)

                relatedEvents = blockParser.getEventsForBlock(events, block=block, seqNum=seqNum)
                for event in relatedEvents:
                    toSet = [blockInfo]
                    if event.blockInfos is not None:
                        existingInfo = event.blockInfos
                        existingInfo.append(blockInfo)
                        toSet = existingInfo

                    # Add the blockInfo to the TMAEvent. Because this is a
                    # frozen dataclass, use object.__setattr__ to set the
                    # attribute. This is the correct way to set a frozen
                    # dataclass attribute after creation.
                    object.__setattr__(event, 'blockInfos', toSet)

    def _makeEventsFromStateTuples(self, states, dayObs, data):
        """For the list of state-tuples, create a list of ``TMAEvent`` objects.

        Given the underlying data, and the start/stop points for each event,
        create the TMAEvent objects for the dayObs.

        Parameters
        ----------
        states : `list` of `tuple`
            The parsed states, as a list of tuples of the form:
                ``(eventStart, eventEnd, eventType, endReason)``
        dayObs : `int`
            The dayObs for the data.
        data : `pd.DataFrame`
            The merged dataframe.

        Returns
        -------
        events : `list` of `lsst.summit.utils.tmaUtils.TMAEvent`
            The events for the specified dayObs.
        """
        seqNum = 0
        events = []
        for parsedState in states:
            begin = data.iloc[parsedState.eventStart]['private_efdStamp']
            end = data.iloc[parsedState.eventEnd]['private_efdStamp']
            beginAstropy = efdTimestampToAstropy(begin)
            endAstropy = efdTimestampToAstropy(end)
            duration = end - begin
            event = TMAEvent(
                dayObs=dayObs,
                seqNum=seqNum,
                type=parsedState.previousState,
                endReason=parsedState.state,
                duration=duration,
                begin=beginAstropy,
                end=endAstropy,
                blockInfos=[],  # this is added later
                _startRow=parsedState.eventStart,
                _endRow=parsedState.eventEnd,
            )
            events.append(event)
            seqNum += 1
        return events

    @staticmethod
    def printTmaDetailedState(tma):
        """Print the full state of all the components of the TMA.

        Currently this is the azimuth and elevation axes' power and motion
        states, and their respective inPosition statuses.

        Parameters
        ----------
        tma : `lsst.summit.utils.tmaUtils.TMAStateMachine`
            The TMA state machine in the state we want to print.
        """
        axes = ['azimuth', 'elevation']
        p = tma._parts
        axisPad = len(max(axes, key=len))  # length of the longest axis string == 9 here, but this is general
        motionPad = max(len(s.name) for s in AxisMotionState)
        powerPad = max(len(s.name) for s in PowerState)

        # example output to show what's being done with the padding:
        #   azimuth - Power:          ON Motion:               STOPPED InPosition: True        # noqa: W505
        # elevation - Power:          ON Motion: MOVING_POINT_TO_POINT InPosition: False       # noqa: W505
        for axis in axes:
            print(f"{axis:>{axisPad}} - "
                  f"Power: {p[f'{axis}SystemState'].name:>{powerPad}} "
                  f"Motion: {p[f'{axis}MotionState'].name:>{motionPad}} "
                  f"InPosition: {p[f'{axis}InPosition']}")
        print(f"Overall system state: {tma.state.name}")

    def printFullDayStateEvolution(self, dayObs, taiOrUtc='utc'):
        """Print the full TMA state evolution for the specified dayObs.

        Replays all the data from the EFD for the specified dayObs through
        the TMA state machine, and prints both the overall and detailed state
        of the TMA for each row.

        Parameters
        ----------
        dayObs : `int`
            The dayObs for which to print the state evolution.
        taiOrUtc : `str`, optional
            Whether to print the timestamps in TAI or UTC. Default is UTC.
        """
        # create a fake event which spans the whole day, and then use
        # printEventDetails code while skipping the header to print the
        # evolution.
        _ = self.getEvents(dayObs)  # ensure the data has been retrieved from the EFD
        data = self._data[dayObs]
        lastRowNum = len(data) - 1

        fakeEvent = TMAEvent(
            dayObs=dayObs,
            seqNum=-1,  # anything will do
            type=TMAState.OFF,  # anything will do
            endReason=TMAState.OFF,  # anything will do
            duration=-1,  # anything will do
            begin=efdTimestampToAstropy(data.iloc[0]['private_efdStamp']),
            end=efdTimestampToAstropy(data.iloc[-1]['private_efdStamp']),
            _startRow=0,
            _endRow=lastRowNum
        )
        self.printEventDetails(fakeEvent, taiOrUtc=taiOrUtc, printHeader=False)

    def printEventDetails(self, event, taiOrUtc='tai', printHeader=True):
        """Print a detailed breakdown of all state transitions during an event.

        Note: this is not the most efficient way to do this, but it is much the
        cleanest with respect to the actual state machine application and event
        generation code, and is easily fast enough for the cases it will be
        used for. It is not worth complicating the normal state machine logic
        to try to use this code.

        Parameters
        ----------
        event : `lsst.summit.utils.tmaUtils.TMAEvent`
            The event to display the details of.
        taiOrUtc : `str`, optional
            Whether to display time strings in TAI or UTC. Defaults to TAI.
            Case insensitive.
        printHeader : `bool`, optional
            Whether to print the event summary. Defaults to True. The primary
            reason for the existence of this option is so that this same
            printing function can be used to show the evolution of a whole day
            by supplying a fake event which spans the whole day, but this event
            necessarily has a meaningless summary, and so needs suppressing.
        """
        taiOrUtc = taiOrUtc.lower()
        if taiOrUtc not in ['tai', 'utc']:
            raise ValueError(f'Got unsuppoted value for {taiOrUtc=}')
        useUtc = taiOrUtc == 'utc'

        if printHeader:
            print(f"Details for {event.duration:.2f}s {event.type.name} event dayObs={event.dayObs}"
                  f" seqNum={event.seqNum}:")
            print(f"- Event began at: {event.begin.utc.isot if useUtc else event.begin.isot}")
            print(f"- Event ended at: {event.end.utc.isot if useUtc else event.end.isot}")

        dayObs = event.dayObs
        data = self._data[dayObs]
        startRow = event._startRow
        endRow = event._endRow
        nRowsToApply = endRow - startRow + 1
        print(f"\nTotal number of rows in the merged dataframe: {len(data)}")
        if printHeader:
            print(f"of which rows {startRow} to {endRow} (inclusive) relate to this event.")

        # reconstruct all the states
        tma = TMAStateMachine(engineeringMode=True)
        _initializeTma(tma)

        tmaStates = {}
        firstAppliedRow = True  # flag to print a header on the first row that's applied
        for rowNum, row in data.iterrows():  # must replay rows right from start to get full correct state
            if rowNum == startRow:
                # we've not yet applied this row, so this is the state just
                # before event
                print(f"\nBefore the event the TMA was in state {tma.state.name}:")
                self.printTmaDetailedState(tma)

            if rowNum >= startRow and rowNum <= endRow:
                if firstAppliedRow:  # only print this intro on the first row we're applying
                    print(f"\nThen, applying the {nRowsToApply} rows of data for this event, the state"
                          " evolved as follows:\n")
                    firstAppliedRow = False

                # break the row down and print its details
                rowFor = row['rowFor']
                axis, rowType = getAxisAndType(rowFor)  # e.g. elevation, MotionState
                value = tma._getRowPayload(row, rowType, rowFor)
                valueStr = f"{str(value) if isinstance(value, bool) else value.name}"
                rowTime = efdTimestampToAstropy(row['private_efdStamp'])
                print(f"On row {rowNum} the {axis} axis had the {rowType} set to {valueStr} at"
                      f" {rowTime.utc.isot if useUtc else rowTime.isot}")

                # then apply it as usual, printing the state right afterwards
                tma.apply(row)
                tmaStates[rowNum] = tma.state
                self.printTmaDetailedState(tma)
                print()

            else:
                # if it's not in the range of interest then just apply it
                # silently as usual
                tma.apply(row)
                tmaStates[rowNum] = tma.state

    def findEvent(self, time):
        """Find the event which contains the specified time.

        If the specified time lies within an event, that event is returned. If
        it is at the exact start, that is logged, and if that start point is
        shared by the end of the previous event, that is logged too. If the
        event lies between events, the events either side are logged, but
        ``None`` is returned. If the time lies before the first event of the
        day a warning is logged, as for times after the last event of the day.

        Parameters
        ----------
        time : `astropy.time.Time`
            The time.

        Returns
        -------
        event : `lsst.summit.utils.tmaUtils.TMAEvent` or `None`
            The event which contains the specified time, or ``None`` if the
            time doesn't fall during an event.
        """
        # there are five possible cases:
        # 1) the time lies before the first event of the day
        # 2) the time lies after the last event of the day
        # 3) the time lies within an event
        #   3a) the time is exactly at the start of an event
        #   3b) if so, time can be shared by the end of the previous event if
        #       they are contiguous
        # 4) the time lies between two events
        # 5) the time is exactly at end of the last event of the day. This is
        #    an issue because event end times are exclusive, so this time is
        #    not technically in that event, it's the moment it closes (and if
        #    there *was* an event which followed contiguously, it would be in
        #    that event instead, which is what motivates this definition of
        #    lies within what event)

        dayObs = getDayObsForTime(time)
        # we know this is on the right day, and definitely before the specified
        # time, but sanity check this before continuing as this needs to be
        # true for this to give the correct answer
        assert getDayObsStartTime(dayObs) <= time
        assert getDayObsEndTime(dayObs) > time

        # command start to many log messages so define once here
        logStart = f"Specified time {time.isot} falls on {dayObs=}"

        events = self.getEvents(dayObs)
        if len(events) == 0:
            self.log.warning(f'There are no events found for {dayObs}')
            return None

        # check case 1)
        if time < events[0].begin:
            self.log.warning(f'{logStart} and is before the first event of the day')
            return None

        # check case 2)
        if time > events[-1].end:
            self.log.warning(f'{logStart} and is after the last event of the day')
            return None

        # check case 5)
        if time == events[-1].end:
            self.log.warning(f'{logStart} and is exactly at the end of the last event of the day'
                             f' (seqnum={events[-1].seqNum}). Because event intervals are half-open, this'
                             ' time does not technically lie in any event')
            return None

        # we are now either in an event, or between events. Walk through the
        # events, and if the end of the event is after the specified time, then
        # we're either in it or past it, so check if we're in.
        for eventNum, event in enumerate(events):
            if event.end > time:  # case 3) we are now into or past the right event
                # the event end encloses the time, so note the > and not >=,
                # this must be strictly greater, we check the overlap case
                # later
                if time >= event.begin:  # we're fully inside the event, so return it.
                    # 3a) before returning, check if we're exactly at the start
                    # of the event, and if so, log it. Then 3b) also check if
                    # we're at the exact end of the previous event, and if so,
                    # log that too.
                    if time == event.begin:
                        self.log.info(f"{logStart} and is exactly at the start of event"
                                      f" {eventNum}")
                        if eventNum == 0:  # I think this is actually impossible, but check anyway
                            return event  # can't check the previous event so return here
                        previousEvent = events[eventNum - 1]
                        if previousEvent.end == time:
                            self.log.info("Previous event is contiguous, so this time is also at the exact"
                                          f" end of {eventNum - 1}")
                    return event
                else:  # case 4)
                    # the event end is past the time, but it's not inside the
                    # event, so we're between events. Log which we're between
                    # and return None
                    previousEvent = events[eventNum - 1]
                    timeAfterPrev = (time - previousEvent.end).to_datetime()
                    naturalTimeAfterPrev = humanize.naturaldelta(timeAfterPrev, minimum_unit='MICROSECONDS')
                    timeBeforeCurrent = (event.begin - time).to_datetime()
                    naturalTimeBeforeCurrent = humanize.naturaldelta(timeBeforeCurrent,
                                                                     minimum_unit='MICROSECONDS')
                    self.log.info(f"{logStart} and lies"
                                  f" {naturalTimeAfterPrev} after the end of event {previousEvent.seqNum}"
                                  f" and {naturalTimeBeforeCurrent} before the start of event {event.seqNum}."
                                  )
                    return None

        raise RuntimeError('Event finding logic fundamentally failed, which should never happen - the code'
                           ' needs fixing')
